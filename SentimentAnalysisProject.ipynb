{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LdQNq7fZywXl"
      ],
      "mount_file_id": "1v156cOh8z-vqp_Vc9mGps4T36COf3YU-",
      "authorship_tag": "ABX9TyORz2DZqcUMAfEAfCUU49Vo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacobTumak/SentimentAnalysisProject/blob/main/SentimentAnalysisProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Sentiment Analysis Project**\n",
        "\n",
        "Author: Jacob Tumak\n",
        "\n",
        "\n",
        "**Description**:\n",
        "\n",
        "I chose to create my own Sentiment Analysis framework as my project because of my interest in machine learning. I enjoy it largely because to me, machine learning is a step towards creations that show progressively human like traits in given areas. I wanted to see what I could create without using pre-built machine learning packages for sentiment analysis. \n",
        "\n",
        "I chose not to use a feature array for the model in order to better show what's happening to each word inside the algorithm (ie; weights, positive and negative distribution, etc). \n",
        "\n",
        "I really enjoyed creating this program and learned a lot about natural language processing along the way."
      ],
      "metadata": {
        "id": "a6gWcQayILlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing**"
      ],
      "metadata": {
        "id": "LdQNq7fZywXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "from dataclasses import dataclass\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "from nltk import (sent_tokenize, word_tokenize)\n",
        "nltk.download(['punkt', 'stopwords', 'wordnet'])\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words(\"english\")\n",
        "stop_words += ['br', \"''\", \"``\"] + list(punctuation)\n",
        "from collections import Counter\n",
        "from pprint import pprint\n",
        "import glob\n",
        "from itertools import islice\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkD41V9W-RlN",
        "outputId": "17ec296b-1dc2-4825-ecc7-00b6dc90a38b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = f\"/content/drive/MyDrive/Train/\"\n",
        "test_dir = f\"/content/drive/MyDrive/Train/Test/\"\n",
        "POS=1;NEG=0\n",
        "\n",
        "def fetch_text(directory, limit=100):\n",
        "  POS = 1; NEG = 0\n",
        "  num_pos = limit//2\n",
        "  num_neg = limit - num_pos\n",
        "  text = []\n",
        "  num_files = 0\n",
        "  while num_files<limit:\n",
        "    for int_type in [POS, NEG]:\n",
        "      if int_type == POS:\n",
        "        n = num_pos; identifier = 'pos'\n",
        "      else:\n",
        "        n = num_neg; identifier = 'neg'\n",
        "      file_paths = glob.glob(directory + identifier + \"/*.txt\")\n",
        "      for file_path in islice(file_paths, n):\n",
        "        with open(file_path, \"r\") as f:\n",
        "          text_id = file_path[len(directory)+4:len(file_path)-4]\n",
        "          text.append(TextFile(text_id, int_type, f.read()))\n",
        "        num_files += 1\n",
        "        output.clear()\n",
        "        print(num_files)    \n",
        "  return text"
      ],
      "metadata": {
        "id": "UGpx8kK_zEK3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def re_init_TextFile(file_list):\n",
        "  text = []\n",
        "  for text_file in file_list:\n",
        "    text.append(TextFile(text_file.name, text_file.identity, text_file.text))\n",
        "  return text"
      ],
      "metadata": {
        "id": "BhM4OGniBGJS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes and Tests"
      ],
      "metadata": {
        "id": "1FiowSfQ9tKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to create word data set:\n",
        "\n",
        "\n",
        "* Import text files into list\n",
        "* remove stopwords and punctuation from each piece of text\n",
        "* stem the remaining words with porter stemmer. Add to seperate lists to represent a review\n",
        "* convert the list into a dict with format: 'word': word-frequency\n",
        "* create a master list of all the words with the difference-score of sentiment calculated by:\n",
        "\n",
        "  $\\text{Word Score}=(\\text{File Value})\\sqrt{|f_{\\text{pos}}^2 - f_{\\text{neg}}^2|}$\n",
        "  \n",
        "  where the $\\text{File Value}$ is $-1$ if the file is negative or $1$ if the file is positive and $f$ is the frequency of positive or negative uses.\n"
      ],
      "metadata": {
        "id": "7ig_hOT-PJo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TextFile class stores data for each individual text file imported from my google drive. "
      ],
      "metadata": {
        "id": "zvfHxiSIjInF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NEG = 0; POS = 1\n",
        "class TextFile:  \n",
        "  def __init__(self, file_name, identity, text):\n",
        "    self.name = file_name\n",
        "    self.text = text\n",
        "    self.identity = identity\n",
        "    self.word_freq = dict()\n",
        "    self.predicted = float()\n",
        "    self.correct = bool\n",
        "    self.__get_freq()\n",
        "\n",
        "  def __get_word_list__(self):\n",
        "    word_list = word_tokenize(self.text)\n",
        "    word_list = [ps.stem(lemmatizer.lemmatize(word)) for word in word_list]\n",
        "    return word_list\n",
        "\n",
        "\n",
        "  def __get_freq(self):\n",
        "    for word in self.__get_word_list__():\n",
        "      if word in self.word_freq:\n",
        "        self.word_freq[word].distribution[self.identity] += 1\n",
        "      else:\n",
        "        self.word_freq[word] = Word([0,0],0)\n",
        "        self.word_freq[word].distribution[self.identity] += 1"
      ],
      "metadata": {
        "id": "W_PR1uyfrvq8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Word\" class stores the statistics for each word collected in the textfiles. This class makes it simple to obtain statistics for a word in a clean and efficeint way."
      ],
      "metadata": {
        "id": "hhnvmR570R9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Word:\n",
        "  distribution: list\n",
        "  score: float"
      ],
      "metadata": {
        "id": "5iauQWGG1bcX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SentimentModel class is used to store statistical word data and use it to make predictions for text that is passed to it. It also contains functions to test various methods of optimizing the data in the class instance"
      ],
      "metadata": {
        "id": "xw1ApAUZ05bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentModel:\n",
        "\n",
        "  def __init__(self, train_files):\n",
        "    self.word_data = dict()\n",
        "    self.add_word_data(train_files)\n",
        "    self.accuracy_dist = list()\n",
        "    self.difference = float()\n",
        "    self.overall = float()\n",
        "    self.num_rated = list()\n",
        "    self.range = float()\n",
        "    \n",
        "\n",
        "\n",
        "  def add_word_data(self, train_files):\n",
        "    for train_file in train_files:\n",
        "      for word in train_file.word_freq:\n",
        "        if word not in self.word_data:\n",
        "          self.word_data[word] = train_file.word_freq[word]\n",
        "        else:\n",
        "          self.word_data[word].distribution[train_file.identity] += train_file.word_freq[word].distribution[train_file.identity]\n",
        "    self.__calc_weights()\n",
        "\n",
        "  def __calc_weights(self):\n",
        "    for word in self.word_data.copy():\n",
        "      dist = self.word_data[word].distribution\n",
        "      if sum(dist) > 10 or abs(np.diff(dist)) > 0.2:\n",
        "        score = np.sqrt(abs(dist[POS]^2 - dist[NEG]^2)) * [-1, 1][dist[NEG] < dist[POS]]\n",
        "        self.word_data[word].score = np.sqrt(abs(dist[POS]^2 - dist[NEG]^2)) * [-1, 1][dist[NEG] < dist[POS]]\n",
        "      else:\n",
        "        self.word_data.pop(word)\n",
        "\n",
        "\n",
        "  def get_rating(self, text_file, exclude=list(), return_result = True):\n",
        "    rating = 0; num_rated = 0\n",
        "    assigned_sent = text_file.identity\n",
        "    for word in text_file.word_freq:\n",
        "      if word in self.word_data and word not in exclude:\n",
        "        word_quantity = text_file.word_freq[word].distribution[assigned_sent]\n",
        "        rating += self.word_data[word].score * word_quantity\n",
        "        num_rated += word_quantity\n",
        "    text_file.predicted = rating/num_rated\n",
        "    compare_result = text_file.predicted + text_file.identity\n",
        "    text_file.correct = compare_result < 0 or compare_result > 1\n",
        "    if return_result: return text_file.correct\n",
        "\n",
        "\n",
        "\n",
        "  def get_accuracy(self, text_files, exclude=list()):\n",
        "    self.num_rated = [0,0]; self.accuracy_dist = [0,0]\n",
        "    for text_file in text_files:\n",
        "      assigned_sent = text_file.identity # 0 if neg, 1 if pos\n",
        "      self.accuracy_dist[assigned_sent] += self.get_rating(text_file, exclude=exclude)\n",
        "      self.num_rated[assigned_sent] += [-1, 1][assigned_sent] # adds one to pos if pos, subtracts one from neg if neg\n",
        "    self.accuracy_dist = np.divide(self.accuracy_dist, self.num_rated)\n",
        "    self.overall = (self.accuracy_dist[POS]-self.accuracy_dist[NEG])/2\n",
        "    self.difference = sum(self.accuracy_dist)\n",
        "\n",
        "  \n",
        "  def optimize_by_word(self, init_test_files, interval=3, max_intervals = 500):\n",
        "    '''Starting from the word with the highest frequency. Accuracy is tested\n",
        "    by removing the given word (or word group if interval > 1). Output is a list\n",
        "    of all removed words.'''\n",
        "\n",
        "    optimized_stopwords = []; words = []\n",
        "    test_files = init_test_files.copy()\n",
        "    iters = 0; improvement = 0\n",
        "    base_rating = self.overall\n",
        "    word_order = dict(sorted(self.word_data.items(), key=lambda x:sum(x[1].score), reverse=False))\n",
        "    for word in word_order:\n",
        "      if iters < max_intervals * interval:\n",
        "        words.append(word)\n",
        "        iters+=1\n",
        "        if iters % interval == 0:\n",
        "          self.get_accuracy(test_files, exclude=words+optimized_stopwords)\n",
        "          if self.overall > improvement:\n",
        "            print(f\"Word: {words}\")\n",
        "            improvement = self.overall\n",
        "            print(f\"  {improvement}\\n  {iters//interval}\")\n",
        "            optimized_stopwords.extend(words)\n",
        "            print()\n",
        "          words = []\n",
        "    print(base_rating, self.overall)\n",
        "    return optimized_stopwords\n",
        "\n",
        "\n",
        "  def optimize_by_file(self, init_test_files):\n",
        "    '''Starting with the most neutral file, this function iterates through\n",
        "    each scored word in the text and tests if the accuracy is increased by removing\n",
        "    the given word. If the accuracy increases, the word remains removed from the model.'''\n",
        "\n",
        "    test_files = init_test_files.copy()\n",
        "    # test_model = self\n",
        "    removed = []; iters = 0\n",
        "    base_rating = self.overall\n",
        "    while iters < 100:\n",
        "      iters += 1\n",
        "      excluded = dict()\n",
        "      improvement = self.overall\n",
        "      m_neutral = self.most_incorrect_prediction(test_files)\n",
        "      print(f\"File: {m_neutral.predicted}\")\n",
        "      for word in m_neutral.word_freq:\n",
        "        self.get_accuracy(test_files, exclude=[word])\n",
        "        excluded[self.overall] = word\n",
        "        max_impact = max(excluded)\n",
        "        if max_impact > improvement:\n",
        "          improvement = max_impact\n",
        "          print(f\"  {max_impact}\")\n",
        "          try: self.word_data.pop(excluded[max_impact])\n",
        "          except: continue\n",
        "      test_files.remove(m_neutral)\n",
        "      print()\n",
        "    return base_rating, self.overall\n",
        "\n",
        "  def most_neutral_file(self, test_files):\n",
        "    '''Iterates through all test files to find the file with the score closest to zero'''\n",
        "    predicted_keys = {test_file.predicted: test_file for test_file in test_files}\n",
        "    return predicted_keys[min(predicted_keys, key=abs)]\n",
        "  \n",
        "  def most_incorrect_prediction(self, test_files):\n",
        "    '''Iterates through all false predicted values to find the value that is furthest from the correct score'''\n",
        "    predicted_keys = {test_file.predicted: test_file for test_file in test_files if test_file.correct == False}\n",
        "    return predicted_keys[max(predicted_keys, key=abs)]"
      ],
      "metadata": {
        "id": "h0yNYmvF08l3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a small work around function built to easily input and rate a single piece of test. 0 is arbitrarily chosen to be used as the identifier for the file. The identifier of a file has no influence over how the file is rated, rather, its used to gather data for word scoring and to get the accuracy of the model by analyzing hundreds of files."
      ],
      "metadata": {
        "id": "zqEZrkCM5KTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rate_my_text(text, model):\n",
        "  trial_text = TextFile(\"trial_text\", 0, text)\n",
        "  model.get_rating(trial_text)\n",
        "  print(f'''Your text is overall {[\"negative\", \"positive\"][int(trial_text.predicted)>0]} with a score of {round(trial_text.predicted,2)}''')\n",
        "\n",
        "text = \"today joe and I went to talk to bob about his alcoholism. He's on a path to recovery now\"\n",
        "rate_my_text(text, test_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlFrgz2xEHIB",
        "outputId": "0a3529dd-379b-4e8e-e51f-3489cfeae74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your text is overall positive with a score of 9.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this time there is no scale for the scoring, so 9.75 isn't scaled but does reflective that the prediction is that the text is positive (since the value is greater than 0)"
      ],
      "metadata": {
        "id": "NDyN_MrrH3F6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimization functions were interesting (albeit slow and inefficient) ways to increase the accuracy of the prediction by eliminating what were essentially waste-words.\n",
        "\n",
        "Ultimately those functions weren't at all effective compared to adjusting the formula used to score each word.\n",
        "\n",
        "I tried multiple formulas, but I came up with this formula before going to sleep one night:\n",
        "\n",
        "\n",
        "  $\\text{Word Score}=(\\text{File Value})\\sqrt{|f_{\\text{pos}}^2 - f_{\\text{neg}}^2|}$\n",
        "\n",
        "I found this to be the most effective way to achieve a high accuracy. Using it to analyze 600 reviews it hasn't been exposed to yet, it achieved an overall accuracy of 98%. This is shown below."
      ],
      "metadata": {
        "id": "-JApzNaK3eTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = fetch_text(train_dir, limit=2000)\n",
        "test_files = fetch_text(test_dir, limit=600)"
      ],
      "metadata": {
        "id": "6MIscQVbjVPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869b1ec8-8d2d-403c-bddf-99e1ad76b5fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = SentimentModel(train_files)"
      ],
      "metadata": {
        "id": "Xs_Ak7mHtiXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model.get_accuracy(test_files)\n",
        "test_model.accuracy_dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtMqoei5lLfh",
        "outputId": "c649f274-9c75-4b91-fbed-db2848c137ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.96,  0.98])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the array above, the first value shown is the accuracy for negative reviews, the second value is the accuracy for positive reviews.\n",
        "\n",
        "I use this format for all the arrays in the model because the integer value for \"False\" in python is 0, which can be used to reference the first value in an arrray. The integer value for \"True\" is 1 and can be used to reference the second value in an array. This is used in code throughout this program in place of if statements and for other simpler ways of choosing a value."
      ],
      "metadata": {
        "id": "Wr7KEEvo5gSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the output when using the ```optimize_word_data``` function on 200 test files. \n",
        "\n",
        "NOTE: This was using words scored by my old formula which was less accurate."
      ],
      "metadata": {
        "id": "8EXdDiosG2k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model.optimize_word_data(test_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixHl5y5SJSXc",
        "outputId": "93f0a88b-ae21-4634-ca2f-98836851e943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: -0.0724097113086383\n",
            "  0.784\n",
            "  0.7875\n",
            "  0.7895\n",
            "  0.7905\n",
            "  0.7925\n",
            "  0.7945\n",
            "  0.796\n",
            "  0.7969999999999999\n",
            "  0.798\n",
            "  0.7985\n",
            "  0.7989999999999999\n",
            "  0.7995\n",
            "  0.8015\n",
            "  0.802\n",
            "\n",
            "File: 0.07140391937191709\n",
            "  0.8023973973973975\n",
            "  0.8038928928928929\n",
            "  0.8043933933933933\n",
            "  0.8048933933933934\n",
            "  0.8053943943943944\n",
            "  0.8058933933933934\n",
            "  0.8063933933933933\n",
            "  0.8073943943943944\n",
            "\n",
            "File: -0.06592395923003835\n",
            "  0.8073073073073074\n",
            "  0.8078078078078078\n",
            "  0.8083083083083084\n",
            "  0.8088088088088088\n",
            "  0.8093093093093093\n",
            "  0.8098098098098099\n",
            "  0.8103103103103103\n",
            "\n",
            "File: -0.06521632633447677\n",
            "  0.8107085040952777\n",
            "  0.8112100076027932\n",
            "  0.8117110096068012\n",
            "  0.8122115101073017\n",
            "  0.8127125121113097\n",
            "  0.8127135151183247\n",
            "  0.8137155191263408\n",
            "  0.8152185251383648\n",
            "  0.8167215311503888\n",
            "\n",
            "File: -0.06068122952253999\n",
            "  0.8171275588527344\n",
            "  0.8176280593532348\n",
            "  0.8181285598537353\n",
            "\n",
            "File: -0.06051749192686449\n",
            "  0.8185354028727523\n",
            "  0.8190343958416247\n",
            "  0.8190374109048808\n",
            "  0.8195394189370093\n",
            "  0.8200414269691378\n",
            "  0.8205419274696384\n",
            "  0.8210439355017669\n",
            "\n",
            "File: 0.059108460379943634\n",
            "  0.8214536144184386\n",
            "  0.822452603357126\n",
            "\n",
            "File: -0.057128486522704046\n",
            "  0.8228683497648563\n",
            "  0.8233753940040887\n",
            "  0.8238779065669026\n",
            "\n",
            "File: -0.0560914082205734\n",
            "  0.824290431970581\n",
            "  0.8247934500792329\n",
            "  0.8252944520832409\n",
            "  0.825795454087249\n",
            "\n",
            "File: 0.05514412705713768\n",
            "  0.8262093169218598\n",
            "\n",
            "File: -0.05371610222706006\n",
            "  0.8266253948148574\n",
            "\n",
            "File: -0.05329889512688539\n",
            "  0.826538587536804\n",
            "\n",
            "File: 0.05219721781184493\n",
            "  0.8269541216991034\n",
            "  0.827455626212644\n",
            "  0.8279571307261846\n",
            "\n",
            "File: 0.05080398999951292\n",
            "  0.8283745476355473\n",
            "  0.828377080471229\n",
            "\n",
            "File: -0.050625864044415395\n",
            "  0.8287948318788696\n",
            "  0.8287968601838658\n",
            "  0.8293014010516762\n",
            "  0.8298059419194864\n",
            "\n",
            "File: -0.049421379126018586\n",
            "  0.8302243540937009\n",
            "\n",
            "File: -0.049334448286287726\n",
            "  0.8306436123997134\n",
            "\n",
            "File: 0.04924049421672824\n",
            "  0.8310637194067503\n",
            "  0.8315662319695645\n",
            "  0.8320687445323784\n",
            "\n",
            "File: -0.048975635248039946\n",
            "  0.8324878420319488\n",
            "\n",
            "File: -0.04830011410040501\n",
            "  0.8329088003196483\n",
            "\n",
            "File: -0.04820342468426596\n",
            "  0.8333306124781141\n",
            "\n",
            "File: -0.04810628872034696\n",
            "  0.8337532811079675\n",
            "\n",
            "File: -0.05585376649576562\n",
            "  0.8316617182771425\n",
            "\n",
            "File: 0.047465303550359696\n",
            "  0.8320861076939767\n",
            "\n",
            "File: 0.04737689852358134\n",
            "  0.832503516476987\n",
            "  0.8330019188234221\n",
            "  0.8335054434961311\n",
            "\n",
            "File: -0.047161542307777866\n",
            "  0.8339252165851737\n",
            "  0.8339298313260919\n",
            "  0.8349471253240573\n",
            "\n",
            "File: -0.044292696455916866\n",
            "  0.8353734150187242\n",
            "  0.8358825799881742\n",
            "  0.8363866122462387\n",
            "\n",
            "File: -0.04375135900783113\n",
            "  0.8368142900595179\n",
            "  0.8373239740554405\n",
            "  0.8378280063135051\n",
            "\n",
            "File: 0.04251869882858258\n",
            "  0.8382570770243581\n",
            "  0.8387611092824226\n",
            "\n",
            "File: 0.04391476551645192\n",
            "  0.8391827467616714\n",
            "\n",
            "File: 0.04158349677391677\n",
            "  0.8396052360338074\n",
            "\n",
            "File: -0.04139481563790006\n",
            "  0.8400285796826314\n",
            "\n",
            "File: -0.0418621746191075\n",
            "  0.8404585269424342\n",
            "\n",
            "File: 0.04178243931894737\n",
            "  0.8414006008837499\n",
            "  0.8419061620566518\n",
            "\n",
            "File: 0.043273524553167006\n",
            "  0.8403065828800411\n",
            "\n",
            "File: 0.040986241201672866\n",
            "  0.840730104860114\n",
            "  0.8412366904730826\n",
            "  0.8417432760860513\n",
            "\n",
            "File: -0.041208809441988695\n",
            "  0.8421686846941019\n",
            "\n",
            "File: -0.04115257725332527\n",
            "  0.8426009164121654\n",
            "\n",
            "File: -0.04089521100277162\n",
            "  0.8430340338509626\n",
            "\n",
            "File: -0.04077931890631446\n",
            "  0.8434680397357882\n",
            "  0.8444936807614292\n",
            "  0.84500078015291\n",
            "  0.8455136006657304\n",
            "\n",
            "File: -0.0417930191888078\n",
            "  0.8459500772623714\n",
            "  0.8464571766538521\n",
            "\n",
            "File: -0.03997511449033104\n",
            "  0.8458668011982764\n",
            "  0.8458735764213897\n",
            "  0.8463806758128705\n",
            "  0.8463874510359837\n",
            "\n",
            "File: -0.039396262840801465\n",
            "  0.8468257247556323\n",
            "  0.8478399235385938\n",
            "  0.8478472274392942\n",
            "\n",
            "File: 0.03858715914762551\n",
            "  0.848286933651972\n",
            "\n",
            "File: -0.03833809267468497\n",
            "  0.8487142356772808\n",
            "  0.8492291687359831\n",
            "\n",
            "File: 0.03780700224259912\n",
            "  0.8496703124182322\n",
            "  0.8501779266314302\n",
            "\n",
            "File: -0.03701059430134911\n",
            "  0.8516375408599446\n",
            "\n",
            "File: 0.03774134882301351\n",
            "  0.8520806589644844\n",
            "  0.8530969191270861\n",
            "\n",
            "File: -0.03673588129945431\n",
            "  0.853527511556103\n",
            "\n",
            "File: 0.03692939640074977\n",
            "  0.8539715451939165\n",
            "\n",
            "File: 0.036702790142848156\n",
            "  0.8544030145932571\n",
            "  0.8549121795627073\n",
            "\n",
            "File: 0.036509380486420245\n",
            "  0.8553450476407107\n",
            "\n",
            "File: -0.03634296175599025\n",
            "  0.855778799122955\n",
            "\n",
            "File: 0.03615520743073674\n",
            "  0.8562237511343731\n",
            "\n",
            "File: -0.03601004766745654\n",
            "  0.8566583887279192\n",
            "\n",
            "File: 0.035282044736099805\n",
            "  0.8571042619650339\n",
            "  0.8576218603087191\n",
            "\n",
            "File: -0.035293711746940536\n",
            "  0.8580573867316998\n",
            "\n",
            "File: -0.03526124699662281\n",
            "  0.8585047204297658\n",
            "\n",
            "File: -0.03520360398490413\n",
            "  0.8589529822060433\n",
            "\n",
            "File: 0.034766613362485856\n",
            "  0.859402174951742\n",
            "\n",
            "File: -0.034912796513951336\n",
            "  0.8598385929334188\n",
            "  0.8603578037330034\n",
            "  0.8614036654050429\n",
            "\n",
            "File: 0.03345615052243865\n",
            "  0.8618559509040573\n",
            "\n",
            "File: -0.035976977962474295\n",
            "  0.8622927388296241\n",
            "\n",
            "File: 0.03299317501071077\n",
            "  0.8627459656095939\n",
            "\n",
            "File: 0.0333057694908282\n",
            "  0.8631836495103925\n",
            "  0.863696470023213\n",
            "\n",
            "File: 0.032991517965531424\n",
            "  0.8641355791686877\n",
            "\n",
            "File: -0.03250211496029205\n",
            "  0.8645755909023338\n",
            "  0.8656161736286606\n",
            "  0.866136464991824\n",
            "\n",
            "File: 0.03239598963270151\n",
            "  0.8660714285714286\n",
            "\n",
            "File: 0.03187192241302247\n",
            "  0.8665123456790124\n",
            "\n",
            "File: 0.03159380699602534\n",
            "  0.8669541709577755\n",
            "\n",
            "File: -0.03136079808376995\n",
            "  0.8673969072164949\n",
            "\n",
            "File: 0.03102796283407186\n",
            "  0.8678531115960569\n",
            "  0.8683744880298421\n",
            "\n",
            "File: -0.03074088417557575\n",
            "  0.8688181380888891\n",
            "\n",
            "File: -0.03364118636177467\n",
            "  0.8692758391127025\n",
            "\n",
            "File: -0.030433885731214295\n",
            "  0.8697344966694811\n",
            "\n",
            "File: 0.030336424737872406\n",
            "  0.8701941137608974\n",
            "\n",
            "File: -0.030169902373266694\n",
            "  0.8706386804522978\n",
            "\n",
            "File: 0.030337635083572567\n",
            "  0.8710992600925966\n",
            "\n",
            "File: 0.02977672580454427\n",
            "  0.871027683178395\n",
            "\n",
            "File: -0.02976378081924903\n",
            "  0.8714735564155096\n",
            "\n",
            "File: -0.029611860633838038\n",
            "  0.8719351016315742\n",
            "  0.8724526999752594\n",
            "  0.8724592106462492\n",
            "\n",
            "File: -0.033475828966764536\n",
            "  0.872922274434661\n",
            "\n",
            "File: 0.029181338687664232\n",
            "  0.8733863110461576\n",
            "\n",
            "File: -0.02908782028553586\n",
            "  0.8738331083728827\n",
            "\n",
            "File: -0.02882589307358704\n",
            "  0.874298120876307\n",
            "\n",
            "File: -0.02998387477572746\n",
            "  0.8747641123534224\n",
            "\n",
            "File: -0.02804334606918735\n",
            "  0.8752310858989829\n",
            "\n",
            "File: 0.027241273140239948\n",
            "  0.8756990446207997\n",
            "\n",
            "File: 0.0269033513571463\n",
            "  0.8761467689129332\n",
            "\n",
            "File: 0.026560936435218185\n",
            "  0.8765954230582174\n",
            "\n",
            "File: 0.026215845743016174\n",
            "  0.8770450099564024\n",
            "  0.877564760476153\n",
            "\n",
            "File: 0.02579050632070655\n",
            "  0.8780158238824712\n",
            "\n",
            "File: -0.025608638841003988\n",
            "  0.8784678270042194\n",
            "\n",
            "File: -0.035430371035795626\n",
            "  0.8789367740232312\n",
            "\n",
            "File: -0.025578986145680223\n",
            "  0.8794067124735729\n",
            "  0.8799429615926708\n",
            "\n",
            "File: 0.025556339468199067\n",
            "  0.8804150132275133\n",
            "  0.8804232804232804\n",
            "\n",
            "File: -0.025533809772633417\n",
            "  0.8808751399992276\n",
            "\n",
            "File: 0.025489770982578878\n",
            "  0.8813487522313144\n",
            "\n",
            "File: 0.02544503942463196\n",
            "  0.88127963447861\n",
            "  0.8817938147977779\n",
            "  0.8823157354658363\n",
            "\n",
            "File: 0.027276470675847594\n",
            "  0.8822481093813648\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7749999999999999, 0.8822481093813648)"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below shows the graph of positive (orange-line) and negative (blue-line) accuracies across a range of different scoring biases. This validates that the most appropriate bias for the model is approximately 0. where score < 0 is negative and score < 0 are positive. The intersection of the lines (red dot) is the ideal value for the bias."
      ],
      "metadata": {
        "id": "AZJEk0vTF6b-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "magnitude = 1\n",
        "\n",
        "neg_accuracy = []; pos_accuracy = []\n",
        "\n",
        "for num in range(-10*magnitude, 10*magnitude):\n",
        "  accuracy = get_accuracy(test_make_text_obj, bias = num/magnitude)\n",
        "\n",
        "  neg_accuracy.append(accuracy['neg'])\n",
        "  pos_accuracy.append(accuracy['pos'])"
      ],
      "metadata": {
        "id": "bEtbIrz7B2C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [number/magnitude for number in range(-10*magnitude, 10*magnitude)]\n",
        "pos_array = np.array(pos_accuracy)\n",
        "neg_array = np.array(neg_accuracy)\n",
        "x_array = np.array(x)\n",
        "\n",
        "plt.plot(x_array, pos_array)\n",
        "plt.plot(x_array, neg_array)\n",
        "\n",
        "idx = np.argwhere(np.diff(np.sign(pos_array - neg_array))).flatten()\n",
        "plt.plot(x_array[idx], neg_array[idx], 'ro')\n",
        "plt.show()\n",
        "\n",
        "x_array[idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "c593MD0dE4rR",
        "outputId": "ee6d2065-6cbb-43df-d8ac-1e4ae4635c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}